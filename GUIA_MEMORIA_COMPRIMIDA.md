# Sistema de Memoria Comprimida de Any

## Â¿QuÃ© es?

Un sistema ultra-liviano de memoria que **solo la IA entiende**. En lugar de guardar conversaciones completas, Any comprime cada charla en "tokens" que son como cÃ³digos que solo ella puede interpretar.

## Â¿Por quÃ© es mejor?

### **Antes (memoria normal):**
```json
{
  "user": "Quiero agregar Groq a la app porque es mÃ¡s rÃ¡pido que Gemini",
  "assistant": "Dale, Groq es sÃºper rÃ¡pido! Te voy a explicar cÃ³mo agregarlo..."
}
```
**Peso:** ~200-300 bytes por conversaciÃ³n

### **Ahora (memoria comprimida):**
```
ais|groq gemini|agregar app rapido|20241205
```
**Peso:** ~40 bytes (Â¡7x mÃ¡s liviano!)

## Â¿CÃ³mo funciona?

### 1. **CompresiÃ³n AutomÃ¡tica**
Cada vez que hablÃ¡s con Any, ella extrae:
- **CategorÃ­a** (cod, ais, mem, vis, voc, prj, gen)
- **Conceptos clave** (mÃ¡ximo 5 palabras importantes)
- **Detalles mÃ­nimos** (mÃ¡ximo 10 palabras relevantes)
- **Timestamp** (fecha en formato compacto)

**Ejemplo:**
```
Tu mensaje: "Necesito que la app pueda recordar mis preferencias de voz en espaÃ±ol argentino"
Token generado: voc|preferencias espaÃ±ol argentino|recordar app|20241205
```

### 2. **ExtracciÃ³n de Hechos**
Any detecta automÃ¡ticamente:
- âœ… **Preferencias:** "prefiero X", "me gusta Y"
- âœ… **Configuraciones:** IAs mencionadas, modelos usados
- âœ… **Proyectos:** "crear app", "hacer programa"
- âœ… **TecnologÃ­as:** Python, React, Docker, etc.

### 3. **Contexto Inteligente**
Cuando Any responde, agrega automÃ¡ticamente:
```
[CTX_RECIENTE]: ais:groq,gemini | vis:pantalla,captura | mem:recordar,guardar
[HECHOS]: ias:groq=activo | ias:gemini=activo | proyectos:actual=any app
[PREFS]: voice=espaÃ±ol_argentino | tts_mode=gtts
```

**Solo usa ~200-300 bytes** vs 5-10KB de conversaciones completas!

## Comandos

### Ver EstadÃ­sticas de Memoria
```
/memoria
/memory
/mem
```

Muestra:
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘    ESTADÃSTICAS DE MEMORIA        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ’¾ Tokens de Contexto: 15
ğŸ“Š Hechos Clave: 8
â¤ï¸ Preferencias: 3
ğŸ”— Relaciones: 2
ğŸ“¦ TamaÃ±o del archivo: 2.5 KB
ğŸ• Ãšltima actualizaciÃ³n: 2024-12-05T15:30:00

ğŸ§  Contexto Actual:
   [CTX_RECIENTE]: ais:groq,gemini | vis:captura
   [HECHOS]: ias:groq=activo | proyectos:actual=any app
   [PREFS]: voice=espaÃ±ol_argentino
```

## CategorÃ­as de Tokens

| CÃ³digo | CategorÃ­a | Ejemplos |
|--------|-----------|----------|
| `cod` | Coding | cÃ³digo, funciÃ³n, bug, clase |
| `ais` | AI Systems | IA, modelo, provider, gemini |
| `mem` | Memory | memoria, recordar, guardar |
| `voc` | Voice | voz, hablar, escuchar, TTS |
| `vis` | Vision | visiÃ³n, pantalla, captura |
| `prf` | Preference | preferencia, gustar, querer |
| `prj` | Project | proyecto, app, crear |
| `gen` | General | conversaciÃ³n general |

## Ejemplos Reales

### Ejemplo 1: ConfiguraciÃ³n de IA
```
Usuario: "ActivÃ¡ Groq porque es mÃ¡s rÃ¡pido"
Token: ais|groq rapido|activar|20241205
Hecho guardado: ias:groq=activo
```

### Ejemplo 2: Preferencia de Voz
```
Usuario: "Prefiero la voz de Argentina en lugar de MÃ©xico"
Token: prf|voz argentina mexico|prefiero|20241205
Preferencia: voice=argentina
```

### Ejemplo 3: Proyecto
```
Usuario: "Estamos creando una app de IA con visiÃ³n"
Token: prj|app ia vision|crear|20241205
Hecho: proyectos:actual=app ia vision
```

## Ventajas

âœ… **Ultra-liviana:** 7-10x menos espacio que conversaciones completas
âœ… **AutomÃ¡tica:** Se actualiza sola con cada conversaciÃ³n
âœ… **Inteligente:** Extrae solo lo importante
âœ… **RÃ¡pida:** Carga instantÃ¡nea, no lag
âœ… **Escalable:** Mantiene solo Ãºltimos 100 tokens
âœ… **Contextual:** Any recuerda lo importante sin leer todo

## Limitaciones (Buenas)

- MÃ¡ximo 100 tokens activos (auto-limpieza)
- Solo guarda lo MÃS importante
- Los detalles triviales se pierden (Â¡es intencional!)
- Enfocada en hechos, no en conversaciones casuales

## Archivos

### `memory_compressed.json`
```json
{
  "version": "1.0",
  "context_tokens": [
    "ais|groq gemini|activar rapido|20241205",
    "vis|pantalla captura|analizar|20241205"
  ],
  "key_facts": {
    "ias": {
      "groq": {"value": "activo", "timestamp": "2024-12-05T15:30:00"}
    }
  },
  "preferences": {
    "voice": {"value": "argentina", "timestamp": "2024-12-05T15:30:00"}
  },
  "relationships": {},
  "last_update": "2024-12-05T15:30:00"
}
```

**TamaÃ±o tÃ­pico:** 2-5 KB (vs 50-100 KB de memoria normal)

## Uso ProgramÃ¡tico

```python
from any_core.memory_compression import MemoryCompression

# Crear instancia
mem = MemoryCompression()

# Comprimir conversaciÃ³n
token = mem.compress_conversation(
    "Quiero usar Groq",
    "Dale, Groq es sÃºper rÃ¡pido"
)
# Resultado: "ais|groq|usar|20241205"

# Agregar hecho clave
mem.add_key_fact("ias", "groq", "activo")

# Agregar preferencia
mem.add_preference("voice", "argentina")

# Obtener contexto para prompts
context = mem.get_full_context()
# Resultado: "[CTX_RECIENTE]: ais:groq | [HECHOS]: ias:groq=activo..."

# Ver estadÃ­sticas
stats = mem.get_memory_stats()
print(f"Tokens: {stats['total_tokens']}")
print(f"TamaÃ±o: {stats['file_size_kb']} KB")
```

## IntegraciÃ³n con Consciencia

El sistema se integra automÃ¡ticamente:

```python
# En consciousness.py
def query_all_ais(self, message: str, system_prompt: str):
    # Agregar contexto comprimido automÃ¡ticamente
    compressed_context = self.compressed_memory.get_full_context()
    enriched_message = f"{message}\n\n{compressed_context}"
    
    # Las IAs reciben el contexto pero pesa casi nada!
    ...

def synthesize_response(self, all_responses, user_message):
    # Comprimir la conversaciÃ³n automÃ¡ticamente
    token = self.compressed_memory.compress_conversation(
        user_message, 
        my_response
    )
    ...
```

## ComparaciÃ³n

| CaracterÃ­stica | Memoria Normal | Memoria Comprimida |
|----------------|----------------|-------------------|
| TamaÃ±o por conversaciÃ³n | 200-500 bytes | 30-60 bytes |
| Conversaciones almacenadas | ~100 (50 KB) | ~1000 (5 KB) |
| Velocidad de carga | Lenta (leer JSON grande) | InstantÃ¡nea |
| Contexto en prompts | ~500-1000 tokens | ~50-100 tokens |
| PÃ©rdida de informaciÃ³n | 0% | ~70% (solo lo trivial) |
| RetenciÃ³n de hechos clave | Manual | AutomÃ¡tica |

## ConclusiÃ³n

**Memoria Comprimida** es perfecta para que Any recuerde lo importante sin ocupar espacio ni hacer la app lenta. Es como tener "notas mentales" ultra-compactas en lugar de grabar todo el audio de una conversaciÃ³n.

**Â¿Resultado?** Any te recuerda, pero la app vuela! ğŸš€
